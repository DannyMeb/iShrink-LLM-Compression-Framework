{
  "initial_metrics": {
    "accuracy": 0.43496503496503497,
    "latency": 26.43728256225586,
    "throughput": 37.825370200025255,
    "memory_footprint": {
      "gpu_allocated": 2366.26220703125,
      "gpu_cached": 18908.0,
      "cpu_memory": 1399.5078125
    },
    "parameter_count": 1235814400
  },
  "pruning_results": {
    "pruned_units": [
      "attn_15_1",
      "attn_15_7",
      "attn_15_6",
      "attn_15_4",
      "attn_15_0",
      "attn_15_5",
      "mlp_15_58",
      "mlp_15_29",
      "mlp_15_46",
      "mlp_15_24",
      "mlp_15_60",
      "mlp_15_52",
      "mlp_15_63",
      "mlp_15_33",
      "mlp_15_41",
      "mlp_15_14",
      "mlp_15_28",
      "mlp_15_47",
      "mlp_15_44",
      "mlp_15_62",
      "mlp_15_10",
      "mlp_15_16",
      "mlp_15_23",
      "mlp_15_55",
      "mlp_15_12",
      "mlp_15_48",
      "mlp_15_30",
      "mlp_15_27",
      "mlp_15_19",
      "mlp_15_4"
    ],
    "memory_reduction_mb": -51.0,
    "final_accuracy": 0.4041958041958042,
    "performance_impact": 0.0707395498392283,
    "layer_statistics": {
      "steps": 4,
      "total_pruned": 30,
      "layer_stats": {
        "15": {
          "units_pruned": 30,
          "accuracy_drops": [
            0.0027972027972028024,
            0.016783216783216814,
            0.03076923076923077
          ],
          "memory_saved": 51.0,
          "is_frozen": true
        }
      }
    }
  },
  "config": {
    "model": {
      "name": "meta-llama/Llama-3.2-1B-Instruct",
      "local_path": "models/Llama-3.2-1B-Instruct",
      "device": "cuda",
      "precision": "float16",
      "batch_size": 8,
      "max_seq_length": 512,
      "low_cpu_mem_usage": true,
      "gradient_checkpointing": true,
      "hidden_size": 768,
      "num_heads": 12,
      "mlp_ratio": 4,
      "tokenizer_kwargs": {
        "padding": true,
        "truncation": true,
        "return_tensors": "pt"
      }
    },
    "pruning": {
      "targets": {
        "min_accuracy": 0.4,
        "min_accuracy_ratio": 0.9,
        "max_pruned_heads": 100,
        "compression_target": 0.9,
        "units_per_step": 10
      },
      "dependency": {
        "hidden_size": 768,
        "num_heads": 12,
        "mlp_ratio": 4,
        "mlp_group_size": 128
      },
      "importance": {
        "num_samples": 100,
        "batch_size": 8,
        "use_mixed_precision": true,
        "memory_efficient": true,
        "gradient_accumulation": true,
        "metric_type": "WIFN",
        "method": "vector_wise",
        "calibration_percent": 0.1,
        "lambda": 0.05
      },
      "env": {
        "max_steps": 1000,
        "eval_frequency": 5,
        "eval_batches": 10,
        "clear_cache": true,
        "max_prune_per_step": 5,
        "reward_weights": {
          "accuracy": 1.0,
          "compression": 0.5,
          "balance": 0.3,
          "violation_penalty": 2.0
        },
        "early_stopping": {
          "patience": 10,
          "min_delta": 0.01
        }
      }
    },
    "rl": {
      "ppo": {
        "hidden_dims": [
          512,
          256
        ],
        "learning_rate": 0.0001,
        "n_epochs": 1,
        "batch_size": 32,
        "clip_ratio": 0.2,
        "value_coef": 0.5,
        "entropy_coef": 0.01,
        "max_grad_norm": 0.5,
        "gamma": 0.99,
        "gae_lambda": 0.95,
        "update_interval": 2048
      }
    },
    "training": {
      "data": {
        "dataset": "cais/mmlu",
        "dataset_config": "all",
        "split": "validation",
        "batch_size": 8,
        "max_seq_length": 512,
        "eval_batch_size": 4,
        "prefetch_factor": 2,
        "eval_split": 0.1,
        "num_workers": 2,
        "shuffle": false
      },
      "optimization": {
        "num_episodes": 100,
        "checkpoint_freq": 10,
        "gradient_accumulation_steps": 4,
        "mixed_precision": true,
        "max_gradient_norm": 1.0,
        "early_stopping": {
          "patience": 5,
          "min_delta": 0.01
        },
        "memory_efficient_backprop": true,
        "offload_optimizer": true,
        "dynamic_batch_sizing": true
      },
      "logging": {
        "log_freq": 1,
        "use_wandb": false,
        "project_name": "llm-pruning-mmlu",
        "metrics_dir": "experiments/results/metrics",
        "log_memory_usage": true,
        "log_dependency_graph": true,
        "log_importance_scores": true
      }
    },
    "metrics": {
      "eval": {
        "num_batches": 50,
        "compute_perplexity": false,
        "measure_latency": true,
        "measure_throughput": true,
        "measure_memory": true
      },
      "thresholds": {
        "min_accuracy": 0.44,
        "max_latency_increase": 0.2,
        "max_memory_usage": 38000
      },
      "save": {
        "dir": "experiments/results/metrics",
        "save_initial": true,
        "save_frequency": 10,
        "format": "json"
      }
    },
    "system": {
      "seed": 42,
      "num_workers": 0,
      "pin_memory": true,
      "log_level": "INFO",
      "save_dir": "experiments/results",
      "checkpoint_dir": "experiments/results/checkpoints",
      "max_memory_usage": 38000,
      "memory_monitoring": true,
      "emergency_memory_recovery": true
    },
    "memory": {
      "gpu_memory_fraction": 0.9,
      "cleanup_interval": 10,
      "batch_auto_scaling": true,
      "min_free_memory": 2000,
      "monitoring": {
        "enabled": true,
        "log_interval": 100,
        "alert_threshold": 0.95
      }
    },
    "checkpointing": {
      "save_dir": "experiments/results/checkpoints",
      "save_frequency": 10,
      "keep_last_n": 5,
      "save_metrics": true,
      "save_importance_scores": true
    }
  }
}