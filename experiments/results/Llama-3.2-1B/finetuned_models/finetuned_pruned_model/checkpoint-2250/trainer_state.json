{
  "best_metric": 0.5768216848373413,
  "best_model_checkpoint": "/home/daniel.gebre/Thesis/LLM-Compression/experiments/results/Llama-3.2-1B/finetuned_models/finetuned_pruned_model/checkpoint-350",
  "epoch": 0.9,
  "eval_steps": 50,
  "global_step": 2250,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.004,
      "grad_norm": 52.45335006713867,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 7.4395,
      "step": 10
    },
    {
      "epoch": 0.008,
      "grad_norm": 57.85764694213867,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 7.5078,
      "step": 20
    },
    {
      "epoch": 0.012,
      "grad_norm": 38.33106994628906,
      "learning_rate": 5.400000000000001e-06,
      "loss": 6.0949,
      "step": 30
    },
    {
      "epoch": 0.016,
      "grad_norm": 36.01114273071289,
      "learning_rate": 7.4e-06,
      "loss": 3.6955,
      "step": 40
    },
    {
      "epoch": 0.02,
      "grad_norm": 6.26161003112793,
      "learning_rate": 9.4e-06,
      "loss": 1.5929,
      "step": 50
    },
    {
      "epoch": 0.02,
      "eval_loss": 0.8158050775527954,
      "eval_runtime": 15.7446,
      "eval_samples_per_second": 16.26,
      "eval_steps_per_second": 16.26,
      "step": 50
    },
    {
      "epoch": 0.024,
      "grad_norm": 0.7743486166000366,
      "learning_rate": 1.14e-05,
      "loss": 0.8928,
      "step": 60
    },
    {
      "epoch": 0.028,
      "grad_norm": 0.706865131855011,
      "learning_rate": 1.3400000000000002e-05,
      "loss": 0.9291,
      "step": 70
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.400537371635437,
      "learning_rate": 1.54e-05,
      "loss": 0.7121,
      "step": 80
    },
    {
      "epoch": 0.036,
      "grad_norm": 0.22767366468906403,
      "learning_rate": 1.7400000000000003e-05,
      "loss": 0.7644,
      "step": 90
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.562168538570404,
      "learning_rate": 1.94e-05,
      "loss": 0.6608,
      "step": 100
    },
    {
      "epoch": 0.04,
      "eval_loss": 0.6167337894439697,
      "eval_runtime": 15.6765,
      "eval_samples_per_second": 16.33,
      "eval_steps_per_second": 16.33,
      "step": 100
    },
    {
      "epoch": 0.044,
      "grad_norm": 0.2282978594303131,
      "learning_rate": 1.994166666666667e-05,
      "loss": 0.8057,
      "step": 110
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.22161519527435303,
      "learning_rate": 1.9858333333333336e-05,
      "loss": 0.5815,
      "step": 120
    },
    {
      "epoch": 0.052,
      "grad_norm": 0.4084140360355377,
      "learning_rate": 1.9775000000000003e-05,
      "loss": 0.8444,
      "step": 130
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.36256852746009827,
      "learning_rate": 1.969166666666667e-05,
      "loss": 0.8897,
      "step": 140
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.20638532936573029,
      "learning_rate": 1.9608333333333337e-05,
      "loss": 0.7276,
      "step": 150
    },
    {
      "epoch": 0.06,
      "eval_loss": 0.59049391746521,
      "eval_runtime": 15.6748,
      "eval_samples_per_second": 16.332,
      "eval_steps_per_second": 16.332,
      "step": 150
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.197761669754982,
      "learning_rate": 1.9525e-05,
      "loss": 0.4845,
      "step": 160
    },
    {
      "epoch": 0.068,
      "grad_norm": 0.2345401793718338,
      "learning_rate": 1.9441666666666667e-05,
      "loss": 0.6358,
      "step": 170
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.36971527338027954,
      "learning_rate": 1.9358333333333334e-05,
      "loss": 0.7184,
      "step": 180
    },
    {
      "epoch": 0.076,
      "grad_norm": 0.44593125581741333,
      "learning_rate": 1.9275e-05,
      "loss": 0.6869,
      "step": 190
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.2846011817455292,
      "learning_rate": 1.9191666666666668e-05,
      "loss": 0.565,
      "step": 200
    },
    {
      "epoch": 0.08,
      "eval_loss": 0.5820530652999878,
      "eval_runtime": 15.6678,
      "eval_samples_per_second": 16.339,
      "eval_steps_per_second": 16.339,
      "step": 200
    },
    {
      "epoch": 0.084,
      "grad_norm": 0.450623482465744,
      "learning_rate": 1.9108333333333335e-05,
      "loss": 0.7896,
      "step": 210
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.36775943636894226,
      "learning_rate": 1.9025e-05,
      "loss": 0.5429,
      "step": 220
    },
    {
      "epoch": 0.092,
      "grad_norm": 0.46103784441947937,
      "learning_rate": 1.894166666666667e-05,
      "loss": 0.7867,
      "step": 230
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.26247090101242065,
      "learning_rate": 1.8858333333333335e-05,
      "loss": 0.6651,
      "step": 240
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.2974027991294861,
      "learning_rate": 1.8775000000000002e-05,
      "loss": 0.7222,
      "step": 250
    },
    {
      "epoch": 0.1,
      "eval_loss": 0.5780166983604431,
      "eval_runtime": 15.6771,
      "eval_samples_per_second": 16.33,
      "eval_steps_per_second": 16.33,
      "step": 250
    },
    {
      "epoch": 0.104,
      "grad_norm": 0.21567374467849731,
      "learning_rate": 1.869166666666667e-05,
      "loss": 0.635,
      "step": 260
    },
    {
      "epoch": 0.108,
      "grad_norm": 0.5653266310691833,
      "learning_rate": 1.8608333333333336e-05,
      "loss": 0.6737,
      "step": 270
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.23338422179222107,
      "learning_rate": 1.8525000000000003e-05,
      "loss": 0.5177,
      "step": 280
    },
    {
      "epoch": 0.116,
      "grad_norm": 0.16523753106594086,
      "learning_rate": 1.844166666666667e-05,
      "loss": 0.5549,
      "step": 290
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.20206575095653534,
      "learning_rate": 1.8358333333333337e-05,
      "loss": 0.5849,
      "step": 300
    },
    {
      "epoch": 0.12,
      "eval_loss": 0.5770426392555237,
      "eval_runtime": 15.6661,
      "eval_samples_per_second": 16.341,
      "eval_steps_per_second": 16.341,
      "step": 300
    },
    {
      "epoch": 0.124,
      "grad_norm": 0.4116422235965729,
      "learning_rate": 1.8275e-05,
      "loss": 0.6218,
      "step": 310
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.4649510681629181,
      "learning_rate": 1.8191666666666667e-05,
      "loss": 0.7051,
      "step": 320
    },
    {
      "epoch": 0.132,
      "grad_norm": 0.23775845766067505,
      "learning_rate": 1.8108333333333334e-05,
      "loss": 0.6421,
      "step": 330
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.2927485704421997,
      "learning_rate": 1.8025e-05,
      "loss": 0.7195,
      "step": 340
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.21677444875240326,
      "learning_rate": 1.7941666666666668e-05,
      "loss": 0.6141,
      "step": 350
    },
    {
      "epoch": 0.14,
      "eval_loss": 0.5768216848373413,
      "eval_runtime": 15.6736,
      "eval_samples_per_second": 16.333,
      "eval_steps_per_second": 16.333,
      "step": 350
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.19935162365436554,
      "learning_rate": 1.7858333333333335e-05,
      "loss": 0.6826,
      "step": 360
    },
    {
      "epoch": 0.148,
      "grad_norm": 0.32162994146347046,
      "learning_rate": 1.7775000000000002e-05,
      "loss": 0.6638,
      "step": 370
    },
    {
      "epoch": 0.152,
      "grad_norm": 0.28050342202186584,
      "learning_rate": 1.769166666666667e-05,
      "loss": 0.4997,
      "step": 380
    },
    {
      "epoch": 0.156,
      "grad_norm": 0.360439270734787,
      "learning_rate": 1.7608333333333336e-05,
      "loss": 0.6626,
      "step": 390
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.20829887688159943,
      "learning_rate": 1.7525000000000002e-05,
      "loss": 0.5685,
      "step": 400
    },
    {
      "epoch": 0.16,
      "eval_loss": 0.579078197479248,
      "eval_runtime": 15.6655,
      "eval_samples_per_second": 16.342,
      "eval_steps_per_second": 16.342,
      "step": 400
    },
    {
      "epoch": 0.164,
      "grad_norm": 0.4165235161781311,
      "learning_rate": 1.744166666666667e-05,
      "loss": 0.7057,
      "step": 410
    },
    {
      "epoch": 0.168,
      "grad_norm": 0.16799461841583252,
      "learning_rate": 1.7358333333333336e-05,
      "loss": 0.497,
      "step": 420
    },
    {
      "epoch": 0.172,
      "grad_norm": 0.548292338848114,
      "learning_rate": 1.7275000000000003e-05,
      "loss": 0.5967,
      "step": 430
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.3834789991378784,
      "learning_rate": 1.719166666666667e-05,
      "loss": 0.3975,
      "step": 440
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.221909299492836,
      "learning_rate": 1.7108333333333337e-05,
      "loss": 0.5892,
      "step": 450
    },
    {
      "epoch": 0.18,
      "eval_loss": 0.5814042091369629,
      "eval_runtime": 15.6711,
      "eval_samples_per_second": 16.336,
      "eval_steps_per_second": 16.336,
      "step": 450
    },
    {
      "epoch": 0.184,
      "grad_norm": 0.42282623052597046,
      "learning_rate": 1.7025e-05,
      "loss": 0.7178,
      "step": 460
    },
    {
      "epoch": 0.188,
      "grad_norm": 0.2778589129447937,
      "learning_rate": 1.6941666666666667e-05,
      "loss": 0.5313,
      "step": 470
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.3595362901687622,
      "learning_rate": 1.6858333333333334e-05,
      "loss": 0.7367,
      "step": 480
    },
    {
      "epoch": 0.196,
      "grad_norm": 0.3930974006652832,
      "learning_rate": 1.6775e-05,
      "loss": 0.3682,
      "step": 490
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.3946440815925598,
      "learning_rate": 1.6691666666666668e-05,
      "loss": 0.3716,
      "step": 500
    },
    {
      "epoch": 0.2,
      "eval_loss": 0.5868872404098511,
      "eval_runtime": 15.6635,
      "eval_samples_per_second": 16.344,
      "eval_steps_per_second": 16.344,
      "step": 500
    },
    {
      "epoch": 0.204,
      "grad_norm": 0.5222020149230957,
      "learning_rate": 1.6608333333333335e-05,
      "loss": 0.5182,
      "step": 510
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.3399554193019867,
      "learning_rate": 1.6525000000000002e-05,
      "loss": 0.5032,
      "step": 520
    },
    {
      "epoch": 0.212,
      "grad_norm": 0.49616101384162903,
      "learning_rate": 1.644166666666667e-05,
      "loss": 0.5026,
      "step": 530
    },
    {
      "epoch": 0.216,
      "grad_norm": 0.5370504856109619,
      "learning_rate": 1.6358333333333332e-05,
      "loss": 0.5323,
      "step": 540
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.3812510073184967,
      "learning_rate": 1.6275e-05,
      "loss": 0.5854,
      "step": 550
    },
    {
      "epoch": 0.22,
      "eval_loss": 0.5921269655227661,
      "eval_runtime": 15.6697,
      "eval_samples_per_second": 16.337,
      "eval_steps_per_second": 16.337,
      "step": 550
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.5157470703125,
      "learning_rate": 1.6191666666666666e-05,
      "loss": 0.5823,
      "step": 560
    },
    {
      "epoch": 0.228,
      "grad_norm": 0.8724538087844849,
      "learning_rate": 1.6108333333333336e-05,
      "loss": 0.547,
      "step": 570
    },
    {
      "epoch": 0.232,
      "grad_norm": 0.4380345940589905,
      "learning_rate": 1.6025000000000003e-05,
      "loss": 0.4751,
      "step": 580
    },
    {
      "epoch": 0.236,
      "grad_norm": 0.42211973667144775,
      "learning_rate": 1.594166666666667e-05,
      "loss": 0.5785,
      "step": 590
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.5209463238716125,
      "learning_rate": 1.5858333333333337e-05,
      "loss": 0.5751,
      "step": 600
    },
    {
      "epoch": 0.24,
      "eval_loss": 0.6013178825378418,
      "eval_runtime": 15.6699,
      "eval_samples_per_second": 16.337,
      "eval_steps_per_second": 16.337,
      "step": 600
    },
    {
      "epoch": 0.244,
      "grad_norm": 0.590548038482666,
      "learning_rate": 1.5775e-05,
      "loss": 0.5897,
      "step": 610
    },
    {
      "epoch": 0.248,
      "grad_norm": 0.43428483605384827,
      "learning_rate": 1.5691666666666667e-05,
      "loss": 0.3679,
      "step": 620
    },
    {
      "epoch": 0.252,
      "grad_norm": 0.41871434450149536,
      "learning_rate": 1.5608333333333334e-05,
      "loss": 0.5784,
      "step": 630
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.599186360836029,
      "learning_rate": 1.5525e-05,
      "loss": 0.4155,
      "step": 640
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8814975023269653,
      "learning_rate": 1.5441666666666668e-05,
      "loss": 0.4839,
      "step": 650
    },
    {
      "epoch": 0.26,
      "eval_loss": 0.6140565872192383,
      "eval_runtime": 15.6748,
      "eval_samples_per_second": 16.332,
      "eval_steps_per_second": 16.332,
      "step": 650
    },
    {
      "epoch": 0.264,
      "grad_norm": 0.7544205188751221,
      "learning_rate": 1.5358333333333335e-05,
      "loss": 0.4953,
      "step": 660
    },
    {
      "epoch": 0.268,
      "grad_norm": 0.9492257833480835,
      "learning_rate": 1.5275000000000002e-05,
      "loss": 0.3974,
      "step": 670
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.525974690914154,
      "learning_rate": 1.5191666666666669e-05,
      "loss": 0.5833,
      "step": 680
    },
    {
      "epoch": 0.276,
      "grad_norm": 0.7406208515167236,
      "learning_rate": 1.5108333333333334e-05,
      "loss": 0.6088,
      "step": 690
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.6654995679855347,
      "learning_rate": 1.5025000000000001e-05,
      "loss": 0.4938,
      "step": 700
    },
    {
      "epoch": 0.28,
      "eval_loss": 0.6198936700820923,
      "eval_runtime": 15.6716,
      "eval_samples_per_second": 16.335,
      "eval_steps_per_second": 16.335,
      "step": 700
    },
    {
      "epoch": 0.284,
      "grad_norm": 0.4249763488769531,
      "learning_rate": 1.4941666666666668e-05,
      "loss": 0.5813,
      "step": 710
    },
    {
      "epoch": 0.288,
      "grad_norm": 1.0750094652175903,
      "learning_rate": 1.4858333333333335e-05,
      "loss": 0.534,
      "step": 720
    },
    {
      "epoch": 0.292,
      "grad_norm": 0.9315818548202515,
      "learning_rate": 1.4775000000000002e-05,
      "loss": 0.4652,
      "step": 730
    },
    {
      "epoch": 0.296,
      "grad_norm": 0.6424024105072021,
      "learning_rate": 1.4691666666666669e-05,
      "loss": 0.5023,
      "step": 740
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.6892701983451843,
      "learning_rate": 1.4608333333333335e-05,
      "loss": 0.4723,
      "step": 750
    },
    {
      "epoch": 0.3,
      "eval_loss": 0.6337121725082397,
      "eval_runtime": 15.6728,
      "eval_samples_per_second": 16.334,
      "eval_steps_per_second": 16.334,
      "step": 750
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.9994946718215942,
      "learning_rate": 1.4525e-05,
      "loss": 0.5466,
      "step": 760
    },
    {
      "epoch": 0.308,
      "grad_norm": 0.4710519313812256,
      "learning_rate": 1.4441666666666668e-05,
      "loss": 0.5588,
      "step": 770
    },
    {
      "epoch": 0.312,
      "grad_norm": 0.587245762348175,
      "learning_rate": 1.4358333333333334e-05,
      "loss": 0.4378,
      "step": 780
    },
    {
      "epoch": 0.316,
      "grad_norm": 0.849619448184967,
      "learning_rate": 1.4275000000000001e-05,
      "loss": 0.5993,
      "step": 790
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.6642155051231384,
      "learning_rate": 1.4191666666666668e-05,
      "loss": 0.4732,
      "step": 800
    },
    {
      "epoch": 0.32,
      "eval_loss": 0.6428794264793396,
      "eval_runtime": 15.6695,
      "eval_samples_per_second": 16.337,
      "eval_steps_per_second": 16.337,
      "step": 800
    },
    {
      "epoch": 0.324,
      "grad_norm": 0.6452877521514893,
      "learning_rate": 1.4108333333333335e-05,
      "loss": 0.442,
      "step": 810
    },
    {
      "epoch": 0.328,
      "grad_norm": 0.5886515974998474,
      "learning_rate": 1.4025000000000002e-05,
      "loss": 0.4362,
      "step": 820
    },
    {
      "epoch": 0.332,
      "grad_norm": 1.0474151372909546,
      "learning_rate": 1.3941666666666669e-05,
      "loss": 0.3974,
      "step": 830
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.6561776995658875,
      "learning_rate": 1.3858333333333334e-05,
      "loss": 0.3924,
      "step": 840
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.168205738067627,
      "learning_rate": 1.3775000000000001e-05,
      "loss": 0.5349,
      "step": 850
    },
    {
      "epoch": 0.34,
      "eval_loss": 0.6528224945068359,
      "eval_runtime": 15.6651,
      "eval_samples_per_second": 16.342,
      "eval_steps_per_second": 16.342,
      "step": 850
    },
    {
      "epoch": 0.344,
      "grad_norm": 0.834452211856842,
      "learning_rate": 1.3691666666666668e-05,
      "loss": 0.3857,
      "step": 860
    },
    {
      "epoch": 0.348,
      "grad_norm": 0.6353026628494263,
      "learning_rate": 1.3608333333333335e-05,
      "loss": 0.4223,
      "step": 870
    },
    {
      "epoch": 0.352,
      "grad_norm": 1.0159960985183716,
      "learning_rate": 1.3525000000000002e-05,
      "loss": 0.4818,
      "step": 880
    },
    {
      "epoch": 0.356,
      "grad_norm": 0.7175406217575073,
      "learning_rate": 1.3441666666666669e-05,
      "loss": 0.4102,
      "step": 890
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.757594108581543,
      "learning_rate": 1.3358333333333336e-05,
      "loss": 0.4317,
      "step": 900
    },
    {
      "epoch": 0.36,
      "eval_loss": 0.6678628921508789,
      "eval_runtime": 15.6723,
      "eval_samples_per_second": 16.335,
      "eval_steps_per_second": 16.335,
      "step": 900
    },
    {
      "epoch": 0.364,
      "grad_norm": 0.6848999261856079,
      "learning_rate": 1.3275e-05,
      "loss": 0.301,
      "step": 910
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.9683360457420349,
      "learning_rate": 1.3191666666666668e-05,
      "loss": 0.4724,
      "step": 920
    },
    {
      "epoch": 0.372,
      "grad_norm": 0.8185216188430786,
      "learning_rate": 1.3108333333333335e-05,
      "loss": 0.3652,
      "step": 930
    },
    {
      "epoch": 0.376,
      "grad_norm": 1.6033111810684204,
      "learning_rate": 1.3025000000000002e-05,
      "loss": 0.4679,
      "step": 940
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.8827179670333862,
      "learning_rate": 1.2941666666666668e-05,
      "loss": 0.4445,
      "step": 950
    },
    {
      "epoch": 0.38,
      "eval_loss": 0.6833285093307495,
      "eval_runtime": 15.6804,
      "eval_samples_per_second": 16.326,
      "eval_steps_per_second": 16.326,
      "step": 950
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.7888917922973633,
      "learning_rate": 1.2858333333333335e-05,
      "loss": 0.3864,
      "step": 960
    },
    {
      "epoch": 0.388,
      "grad_norm": 0.6765183806419373,
      "learning_rate": 1.2775000000000002e-05,
      "loss": 0.4896,
      "step": 970
    },
    {
      "epoch": 0.392,
      "grad_norm": 0.5405011773109436,
      "learning_rate": 1.2691666666666669e-05,
      "loss": 0.3826,
      "step": 980
    },
    {
      "epoch": 0.396,
      "grad_norm": 0.608117401599884,
      "learning_rate": 1.2608333333333334e-05,
      "loss": 0.3719,
      "step": 990
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5920194387435913,
      "learning_rate": 1.2525000000000001e-05,
      "loss": 0.2878,
      "step": 1000
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.6999462842941284,
      "eval_runtime": 15.6765,
      "eval_samples_per_second": 16.33,
      "eval_steps_per_second": 16.33,
      "step": 1000
    },
    {
      "epoch": 0.404,
      "grad_norm": 0.7866901755332947,
      "learning_rate": 1.2441666666666668e-05,
      "loss": 0.3332,
      "step": 1010
    },
    {
      "epoch": 0.408,
      "grad_norm": 0.8284808993339539,
      "learning_rate": 1.2358333333333335e-05,
      "loss": 0.2891,
      "step": 1020
    },
    {
      "epoch": 0.412,
      "grad_norm": 0.7971327304840088,
      "learning_rate": 1.2275000000000002e-05,
      "loss": 0.3178,
      "step": 1030
    },
    {
      "epoch": 0.416,
      "grad_norm": 1.423455834388733,
      "learning_rate": 1.2191666666666669e-05,
      "loss": 0.3114,
      "step": 1040
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.7472359538078308,
      "learning_rate": 1.2108333333333336e-05,
      "loss": 0.4674,
      "step": 1050
    },
    {
      "epoch": 0.42,
      "eval_loss": 0.7038415670394897,
      "eval_runtime": 15.6754,
      "eval_samples_per_second": 16.331,
      "eval_steps_per_second": 16.331,
      "step": 1050
    },
    {
      "epoch": 0.424,
      "grad_norm": 0.5667435526847839,
      "learning_rate": 1.2025e-05,
      "loss": 0.4008,
      "step": 1060
    },
    {
      "epoch": 0.428,
      "grad_norm": 1.5997567176818848,
      "learning_rate": 1.1941666666666666e-05,
      "loss": 0.3673,
      "step": 1070
    },
    {
      "epoch": 0.432,
      "grad_norm": 1.4507145881652832,
      "learning_rate": 1.1858333333333335e-05,
      "loss": 0.5612,
      "step": 1080
    },
    {
      "epoch": 0.436,
      "grad_norm": 0.8523694276809692,
      "learning_rate": 1.1775000000000002e-05,
      "loss": 0.4181,
      "step": 1090
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.9056517481803894,
      "learning_rate": 1.1691666666666669e-05,
      "loss": 0.2778,
      "step": 1100
    },
    {
      "epoch": 0.44,
      "eval_loss": 0.7218762636184692,
      "eval_runtime": 15.6674,
      "eval_samples_per_second": 16.34,
      "eval_steps_per_second": 16.34,
      "step": 1100
    },
    {
      "epoch": 0.444,
      "grad_norm": 1.6378074884414673,
      "learning_rate": 1.1608333333333335e-05,
      "loss": 0.4327,
      "step": 1110
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.8940889835357666,
      "learning_rate": 1.1525000000000002e-05,
      "loss": 0.3382,
      "step": 1120
    },
    {
      "epoch": 0.452,
      "grad_norm": 0.6879273653030396,
      "learning_rate": 1.144166666666667e-05,
      "loss": 0.2002,
      "step": 1130
    },
    {
      "epoch": 0.456,
      "grad_norm": 1.1894093751907349,
      "learning_rate": 1.1358333333333333e-05,
      "loss": 0.2588,
      "step": 1140
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.8007060885429382,
      "learning_rate": 1.1275e-05,
      "loss": 0.3137,
      "step": 1150
    },
    {
      "epoch": 0.46,
      "eval_loss": 0.7302736043930054,
      "eval_runtime": 15.6699,
      "eval_samples_per_second": 16.337,
      "eval_steps_per_second": 16.337,
      "step": 1150
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.9749451875686646,
      "learning_rate": 1.1191666666666667e-05,
      "loss": 0.3374,
      "step": 1160
    },
    {
      "epoch": 0.468,
      "grad_norm": 1.0770039558410645,
      "learning_rate": 1.1108333333333335e-05,
      "loss": 0.39,
      "step": 1170
    },
    {
      "epoch": 0.472,
      "grad_norm": 0.7623720765113831,
      "learning_rate": 1.1025000000000002e-05,
      "loss": 0.2788,
      "step": 1180
    },
    {
      "epoch": 0.476,
      "grad_norm": 0.8977556824684143,
      "learning_rate": 1.0941666666666669e-05,
      "loss": 0.2875,
      "step": 1190
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.9450139999389648,
      "learning_rate": 1.0858333333333336e-05,
      "loss": 0.393,
      "step": 1200
    },
    {
      "epoch": 0.48,
      "eval_loss": 0.7438771724700928,
      "eval_runtime": 15.6713,
      "eval_samples_per_second": 16.336,
      "eval_steps_per_second": 16.336,
      "step": 1200
    },
    {
      "epoch": 0.484,
      "grad_norm": 1.0469765663146973,
      "learning_rate": 1.0775e-05,
      "loss": 0.3985,
      "step": 1210
    },
    {
      "epoch": 0.488,
      "grad_norm": 0.6336680054664612,
      "learning_rate": 1.0691666666666666e-05,
      "loss": 0.2168,
      "step": 1220
    },
    {
      "epoch": 0.492,
      "grad_norm": 0.8799635767936707,
      "learning_rate": 1.0608333333333333e-05,
      "loss": 0.2958,
      "step": 1230
    },
    {
      "epoch": 0.496,
      "grad_norm": 1.215141773223877,
      "learning_rate": 1.0525e-05,
      "loss": 0.3331,
      "step": 1240
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.9874415397644043,
      "learning_rate": 1.0441666666666667e-05,
      "loss": 0.363,
      "step": 1250
    },
    {
      "epoch": 0.5,
      "eval_loss": 0.7544496059417725,
      "eval_runtime": 15.673,
      "eval_samples_per_second": 16.334,
      "eval_steps_per_second": 16.334,
      "step": 1250
    },
    {
      "epoch": 0.504,
      "grad_norm": 1.3980766534805298,
      "learning_rate": 1.0358333333333336e-05,
      "loss": 0.4599,
      "step": 1260
    },
    {
      "epoch": 0.508,
      "grad_norm": 0.7678541541099548,
      "learning_rate": 1.0275000000000002e-05,
      "loss": 0.2458,
      "step": 1270
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.5773842930793762,
      "learning_rate": 1.019166666666667e-05,
      "loss": 0.3103,
      "step": 1280
    },
    {
      "epoch": 0.516,
      "grad_norm": 0.9937810301780701,
      "learning_rate": 1.0108333333333333e-05,
      "loss": 0.3539,
      "step": 1290
    },
    {
      "epoch": 0.52,
      "grad_norm": 1.6834417581558228,
      "learning_rate": 1.0025e-05,
      "loss": 0.2458,
      "step": 1300
    },
    {
      "epoch": 0.52,
      "eval_loss": 0.7715816497802734,
      "eval_runtime": 15.6681,
      "eval_samples_per_second": 16.339,
      "eval_steps_per_second": 16.339,
      "step": 1300
    },
    {
      "epoch": 0.524,
      "grad_norm": 1.5411217212677002,
      "learning_rate": 9.941666666666667e-06,
      "loss": 0.2886,
      "step": 1310
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.8436856269836426,
      "learning_rate": 9.858333333333334e-06,
      "loss": 0.4412,
      "step": 1320
    },
    {
      "epoch": 0.532,
      "grad_norm": 1.602514624595642,
      "learning_rate": 9.775e-06,
      "loss": 0.358,
      "step": 1330
    },
    {
      "epoch": 0.536,
      "grad_norm": 1.7220467329025269,
      "learning_rate": 9.691666666666667e-06,
      "loss": 0.3635,
      "step": 1340
    },
    {
      "epoch": 0.54,
      "grad_norm": 0.5138055086135864,
      "learning_rate": 9.608333333333334e-06,
      "loss": 0.3059,
      "step": 1350
    },
    {
      "epoch": 0.54,
      "eval_loss": 0.7735248804092407,
      "eval_runtime": 15.6693,
      "eval_samples_per_second": 16.338,
      "eval_steps_per_second": 16.338,
      "step": 1350
    },
    {
      "epoch": 0.544,
      "grad_norm": 1.8380587100982666,
      "learning_rate": 9.525000000000001e-06,
      "loss": 0.3615,
      "step": 1360
    },
    {
      "epoch": 0.548,
      "grad_norm": 1.583900809288025,
      "learning_rate": 9.441666666666668e-06,
      "loss": 0.3627,
      "step": 1370
    },
    {
      "epoch": 0.552,
      "grad_norm": 0.8210024237632751,
      "learning_rate": 9.358333333333333e-06,
      "loss": 0.2741,
      "step": 1380
    },
    {
      "epoch": 0.556,
      "grad_norm": 1.0527563095092773,
      "learning_rate": 9.275e-06,
      "loss": 0.2421,
      "step": 1390
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.9086163640022278,
      "learning_rate": 9.191666666666667e-06,
      "loss": 0.2763,
      "step": 1400
    },
    {
      "epoch": 0.56,
      "eval_loss": 0.7923173904418945,
      "eval_runtime": 15.6713,
      "eval_samples_per_second": 16.336,
      "eval_steps_per_second": 16.336,
      "step": 1400
    },
    {
      "epoch": 0.564,
      "grad_norm": 1.284328818321228,
      "learning_rate": 9.108333333333334e-06,
      "loss": 0.2324,
      "step": 1410
    },
    {
      "epoch": 0.568,
      "grad_norm": 2.969379186630249,
      "learning_rate": 9.025e-06,
      "loss": 0.2981,
      "step": 1420
    },
    {
      "epoch": 0.572,
      "grad_norm": 1.138113260269165,
      "learning_rate": 8.941666666666668e-06,
      "loss": 0.3417,
      "step": 1430
    },
    {
      "epoch": 0.576,
      "grad_norm": 1.0161796808242798,
      "learning_rate": 8.858333333333335e-06,
      "loss": 0.3103,
      "step": 1440
    },
    {
      "epoch": 0.58,
      "grad_norm": 1.5472160577774048,
      "learning_rate": 8.775e-06,
      "loss": 0.3668,
      "step": 1450
    },
    {
      "epoch": 0.58,
      "eval_loss": 0.8006560802459717,
      "eval_runtime": 15.673,
      "eval_samples_per_second": 16.334,
      "eval_steps_per_second": 16.334,
      "step": 1450
    },
    {
      "epoch": 0.584,
      "grad_norm": 1.34811532497406,
      "learning_rate": 8.691666666666667e-06,
      "loss": 0.3444,
      "step": 1460
    },
    {
      "epoch": 0.588,
      "grad_norm": 2.077671527862549,
      "learning_rate": 8.608333333333334e-06,
      "loss": 0.3178,
      "step": 1470
    },
    {
      "epoch": 0.592,
      "grad_norm": 2.183802604675293,
      "learning_rate": 8.525e-06,
      "loss": 0.2671,
      "step": 1480
    },
    {
      "epoch": 0.596,
      "grad_norm": 1.5492039918899536,
      "learning_rate": 8.441666666666667e-06,
      "loss": 0.2914,
      "step": 1490
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.8267010450363159,
      "learning_rate": 8.358333333333334e-06,
      "loss": 0.2687,
      "step": 1500
    },
    {
      "epoch": 0.6,
      "eval_loss": 0.8123871684074402,
      "eval_runtime": 15.6672,
      "eval_samples_per_second": 16.34,
      "eval_steps_per_second": 16.34,
      "step": 1500
    },
    {
      "epoch": 0.604,
      "grad_norm": 0.6992261409759521,
      "learning_rate": 8.275000000000001e-06,
      "loss": 0.2511,
      "step": 1510
    },
    {
      "epoch": 0.608,
      "grad_norm": 1.9564731121063232,
      "learning_rate": 8.191666666666668e-06,
      "loss": 0.2995,
      "step": 1520
    },
    {
      "epoch": 0.612,
      "grad_norm": 0.9198412895202637,
      "learning_rate": 8.108333333333333e-06,
      "loss": 0.231,
      "step": 1530
    },
    {
      "epoch": 0.616,
      "grad_norm": 0.823914110660553,
      "learning_rate": 8.025e-06,
      "loss": 0.1767,
      "step": 1540
    },
    {
      "epoch": 0.62,
      "grad_norm": 1.772864818572998,
      "learning_rate": 7.941666666666667e-06,
      "loss": 0.2841,
      "step": 1550
    },
    {
      "epoch": 0.62,
      "eval_loss": 0.8203080296516418,
      "eval_runtime": 15.6722,
      "eval_samples_per_second": 16.335,
      "eval_steps_per_second": 16.335,
      "step": 1550
    },
    {
      "epoch": 0.624,
      "grad_norm": 1.2386095523834229,
      "learning_rate": 7.858333333333334e-06,
      "loss": 0.2571,
      "step": 1560
    },
    {
      "epoch": 0.628,
      "grad_norm": 1.1620148420333862,
      "learning_rate": 7.775000000000001e-06,
      "loss": 0.3067,
      "step": 1570
    },
    {
      "epoch": 0.632,
      "grad_norm": 1.3037523031234741,
      "learning_rate": 7.691666666666668e-06,
      "loss": 0.1793,
      "step": 1580
    },
    {
      "epoch": 0.636,
      "grad_norm": 2.2957873344421387,
      "learning_rate": 7.608333333333334e-06,
      "loss": 0.3006,
      "step": 1590
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.7707515358924866,
      "learning_rate": 7.525e-06,
      "loss": 0.3278,
      "step": 1600
    },
    {
      "epoch": 0.64,
      "eval_loss": 0.8282981514930725,
      "eval_runtime": 15.6684,
      "eval_samples_per_second": 16.339,
      "eval_steps_per_second": 16.339,
      "step": 1600
    },
    {
      "epoch": 0.644,
      "grad_norm": 1.561239242553711,
      "learning_rate": 7.441666666666667e-06,
      "loss": 0.2767,
      "step": 1610
    },
    {
      "epoch": 0.648,
      "grad_norm": 1.1623082160949707,
      "learning_rate": 7.358333333333334e-06,
      "loss": 0.181,
      "step": 1620
    },
    {
      "epoch": 0.652,
      "grad_norm": 1.441716194152832,
      "learning_rate": 7.275000000000001e-06,
      "loss": 0.3634,
      "step": 1630
    },
    {
      "epoch": 0.656,
      "grad_norm": 2.2550721168518066,
      "learning_rate": 7.191666666666667e-06,
      "loss": 0.1659,
      "step": 1640
    },
    {
      "epoch": 0.66,
      "grad_norm": 0.7218365669250488,
      "learning_rate": 7.108333333333334e-06,
      "loss": 0.1921,
      "step": 1650
    },
    {
      "epoch": 0.66,
      "eval_loss": 0.8371651768684387,
      "eval_runtime": 15.6707,
      "eval_samples_per_second": 16.336,
      "eval_steps_per_second": 16.336,
      "step": 1650
    },
    {
      "epoch": 0.664,
      "grad_norm": 1.2758680582046509,
      "learning_rate": 7.0250000000000005e-06,
      "loss": 0.2414,
      "step": 1660
    },
    {
      "epoch": 0.668,
      "grad_norm": 0.9265143871307373,
      "learning_rate": 6.941666666666667e-06,
      "loss": 0.265,
      "step": 1670
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.9859113097190857,
      "learning_rate": 6.8583333333333335e-06,
      "loss": 0.3487,
      "step": 1680
    },
    {
      "epoch": 0.676,
      "grad_norm": 1.5087882280349731,
      "learning_rate": 6.775e-06,
      "loss": 0.2535,
      "step": 1690
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.921674370765686,
      "learning_rate": 6.691666666666667e-06,
      "loss": 0.2872,
      "step": 1700
    },
    {
      "epoch": 0.68,
      "eval_loss": 0.8461257219314575,
      "eval_runtime": 15.6704,
      "eval_samples_per_second": 16.337,
      "eval_steps_per_second": 16.337,
      "step": 1700
    },
    {
      "epoch": 0.684,
      "grad_norm": 0.8631421327590942,
      "learning_rate": 6.608333333333334e-06,
      "loss": 0.2177,
      "step": 1710
    },
    {
      "epoch": 0.688,
      "grad_norm": 1.0557804107666016,
      "learning_rate": 6.525e-06,
      "loss": 0.2226,
      "step": 1720
    },
    {
      "epoch": 0.692,
      "grad_norm": 1.3219667673110962,
      "learning_rate": 6.441666666666667e-06,
      "loss": 0.2165,
      "step": 1730
    },
    {
      "epoch": 0.696,
      "grad_norm": 1.312997817993164,
      "learning_rate": 6.358333333333334e-06,
      "loss": 0.21,
      "step": 1740
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.8787145018577576,
      "learning_rate": 6.275e-06,
      "loss": 0.1653,
      "step": 1750
    },
    {
      "epoch": 0.7,
      "eval_loss": 0.8585291504859924,
      "eval_runtime": 15.6736,
      "eval_samples_per_second": 16.333,
      "eval_steps_per_second": 16.333,
      "step": 1750
    },
    {
      "epoch": 0.704,
      "grad_norm": 1.5288691520690918,
      "learning_rate": 6.191666666666667e-06,
      "loss": 0.229,
      "step": 1760
    },
    {
      "epoch": 0.708,
      "grad_norm": 0.6049493551254272,
      "learning_rate": 6.108333333333334e-06,
      "loss": 0.2496,
      "step": 1770
    },
    {
      "epoch": 0.712,
      "grad_norm": 0.9701728224754333,
      "learning_rate": 6.025000000000001e-06,
      "loss": 0.2567,
      "step": 1780
    },
    {
      "epoch": 0.716,
      "grad_norm": 2.093064069747925,
      "learning_rate": 5.941666666666667e-06,
      "loss": 0.2583,
      "step": 1790
    },
    {
      "epoch": 0.72,
      "grad_norm": 2.134310483932495,
      "learning_rate": 5.858333333333334e-06,
      "loss": 0.2636,
      "step": 1800
    },
    {
      "epoch": 0.72,
      "eval_loss": 0.8557276725769043,
      "eval_runtime": 15.6701,
      "eval_samples_per_second": 16.337,
      "eval_steps_per_second": 16.337,
      "step": 1800
    },
    {
      "epoch": 0.724,
      "grad_norm": 1.50175940990448,
      "learning_rate": 5.775000000000001e-06,
      "loss": 0.187,
      "step": 1810
    },
    {
      "epoch": 0.728,
      "grad_norm": 1.1380314826965332,
      "learning_rate": 5.6916666666666675e-06,
      "loss": 0.2111,
      "step": 1820
    },
    {
      "epoch": 0.732,
      "grad_norm": 1.1410568952560425,
      "learning_rate": 5.6083333333333336e-06,
      "loss": 0.2372,
      "step": 1830
    },
    {
      "epoch": 0.736,
      "grad_norm": 1.0089960098266602,
      "learning_rate": 5.5250000000000005e-06,
      "loss": 0.2211,
      "step": 1840
    },
    {
      "epoch": 0.74,
      "grad_norm": 1.0403265953063965,
      "learning_rate": 5.441666666666667e-06,
      "loss": 0.2092,
      "step": 1850
    },
    {
      "epoch": 0.74,
      "eval_loss": 0.865810751914978,
      "eval_runtime": 15.669,
      "eval_samples_per_second": 16.338,
      "eval_steps_per_second": 16.338,
      "step": 1850
    },
    {
      "epoch": 0.744,
      "grad_norm": 0.8717373013496399,
      "learning_rate": 5.358333333333334e-06,
      "loss": 0.2522,
      "step": 1860
    },
    {
      "epoch": 0.748,
      "grad_norm": 0.5814410448074341,
      "learning_rate": 5.275e-06,
      "loss": 0.1569,
      "step": 1870
    },
    {
      "epoch": 0.752,
      "grad_norm": 2.165043354034424,
      "learning_rate": 5.191666666666667e-06,
      "loss": 0.2035,
      "step": 1880
    },
    {
      "epoch": 0.756,
      "grad_norm": 1.9257919788360596,
      "learning_rate": 5.108333333333334e-06,
      "loss": 0.2112,
      "step": 1890
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.1175565719604492,
      "learning_rate": 5.025e-06,
      "loss": 0.2105,
      "step": 1900
    },
    {
      "epoch": 0.76,
      "eval_loss": 0.8634572625160217,
      "eval_runtime": 15.6705,
      "eval_samples_per_second": 16.336,
      "eval_steps_per_second": 16.336,
      "step": 1900
    },
    {
      "epoch": 0.764,
      "grad_norm": 1.840101957321167,
      "learning_rate": 4.941666666666667e-06,
      "loss": 0.2331,
      "step": 1910
    },
    {
      "epoch": 0.768,
      "grad_norm": 2.660146951675415,
      "learning_rate": 4.858333333333334e-06,
      "loss": 0.2348,
      "step": 1920
    },
    {
      "epoch": 0.772,
      "grad_norm": 0.9553210735321045,
      "learning_rate": 4.775e-06,
      "loss": 0.2432,
      "step": 1930
    },
    {
      "epoch": 0.776,
      "grad_norm": 1.3298882246017456,
      "learning_rate": 4.691666666666667e-06,
      "loss": 0.2714,
      "step": 1940
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.8519226312637329,
      "learning_rate": 4.608333333333334e-06,
      "loss": 0.1869,
      "step": 1950
    },
    {
      "epoch": 0.78,
      "eval_loss": 0.8774974942207336,
      "eval_runtime": 15.6696,
      "eval_samples_per_second": 16.337,
      "eval_steps_per_second": 16.337,
      "step": 1950
    },
    {
      "epoch": 0.784,
      "grad_norm": 1.48677396774292,
      "learning_rate": 4.525000000000001e-06,
      "loss": 0.2553,
      "step": 1960
    },
    {
      "epoch": 0.788,
      "grad_norm": 0.684501588344574,
      "learning_rate": 4.441666666666667e-06,
      "loss": 0.2367,
      "step": 1970
    },
    {
      "epoch": 0.792,
      "grad_norm": 2.2385833263397217,
      "learning_rate": 4.358333333333334e-06,
      "loss": 0.2069,
      "step": 1980
    },
    {
      "epoch": 0.796,
      "grad_norm": 0.7394872307777405,
      "learning_rate": 4.2750000000000006e-06,
      "loss": 0.2192,
      "step": 1990
    },
    {
      "epoch": 0.8,
      "grad_norm": 1.6040723323822021,
      "learning_rate": 4.1916666666666675e-06,
      "loss": 0.2731,
      "step": 2000
    },
    {
      "epoch": 0.8,
      "eval_loss": 0.8835316896438599,
      "eval_runtime": 15.6668,
      "eval_samples_per_second": 16.34,
      "eval_steps_per_second": 16.34,
      "step": 2000
    },
    {
      "epoch": 0.804,
      "grad_norm": 1.9511781930923462,
      "learning_rate": 4.1083333333333335e-06,
      "loss": 0.1876,
      "step": 2010
    },
    {
      "epoch": 0.808,
      "grad_norm": 1.5629044771194458,
      "learning_rate": 4.0250000000000004e-06,
      "loss": 0.2847,
      "step": 2020
    },
    {
      "epoch": 0.812,
      "grad_norm": 1.1156597137451172,
      "learning_rate": 3.941666666666667e-06,
      "loss": 0.1731,
      "step": 2030
    },
    {
      "epoch": 0.816,
      "grad_norm": 1.5963433980941772,
      "learning_rate": 3.858333333333333e-06,
      "loss": 0.2871,
      "step": 2040
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.0903856754302979,
      "learning_rate": 3.7750000000000003e-06,
      "loss": 0.2097,
      "step": 2050
    },
    {
      "epoch": 0.82,
      "eval_loss": 0.8929300308227539,
      "eval_runtime": 15.6711,
      "eval_samples_per_second": 16.336,
      "eval_steps_per_second": 16.336,
      "step": 2050
    },
    {
      "epoch": 0.824,
      "grad_norm": 1.2310140132904053,
      "learning_rate": 3.6916666666666668e-06,
      "loss": 0.1832,
      "step": 2060
    },
    {
      "epoch": 0.828,
      "grad_norm": 1.9908190965652466,
      "learning_rate": 3.6083333333333337e-06,
      "loss": 0.2082,
      "step": 2070
    },
    {
      "epoch": 0.832,
      "grad_norm": 1.6315706968307495,
      "learning_rate": 3.525e-06,
      "loss": 0.2523,
      "step": 2080
    },
    {
      "epoch": 0.836,
      "grad_norm": 2.272608995437622,
      "learning_rate": 3.441666666666667e-06,
      "loss": 0.2318,
      "step": 2090
    },
    {
      "epoch": 0.84,
      "grad_norm": 1.2632986307144165,
      "learning_rate": 3.3583333333333335e-06,
      "loss": 0.2268,
      "step": 2100
    },
    {
      "epoch": 0.84,
      "eval_loss": 0.8961852192878723,
      "eval_runtime": 15.6706,
      "eval_samples_per_second": 16.336,
      "eval_steps_per_second": 16.336,
      "step": 2100
    },
    {
      "epoch": 0.844,
      "grad_norm": 1.109336256980896,
      "learning_rate": 3.2750000000000004e-06,
      "loss": 0.2134,
      "step": 2110
    },
    {
      "epoch": 0.848,
      "grad_norm": 1.003001093864441,
      "learning_rate": 3.191666666666667e-06,
      "loss": 0.1502,
      "step": 2120
    },
    {
      "epoch": 0.852,
      "grad_norm": 1.301186442375183,
      "learning_rate": 3.1083333333333338e-06,
      "loss": 0.1807,
      "step": 2130
    },
    {
      "epoch": 0.856,
      "grad_norm": 1.6731882095336914,
      "learning_rate": 3.0250000000000003e-06,
      "loss": 0.1487,
      "step": 2140
    },
    {
      "epoch": 0.86,
      "grad_norm": 0.8336707353591919,
      "learning_rate": 2.941666666666667e-06,
      "loss": 0.234,
      "step": 2150
    },
    {
      "epoch": 0.86,
      "eval_loss": 0.902674674987793,
      "eval_runtime": 15.6705,
      "eval_samples_per_second": 16.336,
      "eval_steps_per_second": 16.336,
      "step": 2150
    },
    {
      "epoch": 0.864,
      "grad_norm": 2.0470917224884033,
      "learning_rate": 2.8583333333333336e-06,
      "loss": 0.2059,
      "step": 2160
    },
    {
      "epoch": 0.868,
      "grad_norm": 1.2296267747879028,
      "learning_rate": 2.7750000000000005e-06,
      "loss": 0.2094,
      "step": 2170
    },
    {
      "epoch": 0.872,
      "grad_norm": 1.443036437034607,
      "learning_rate": 2.691666666666667e-06,
      "loss": 0.1926,
      "step": 2180
    },
    {
      "epoch": 0.876,
      "grad_norm": 1.2643933296203613,
      "learning_rate": 2.608333333333333e-06,
      "loss": 0.2317,
      "step": 2190
    },
    {
      "epoch": 0.88,
      "grad_norm": 1.89468514919281,
      "learning_rate": 2.5250000000000004e-06,
      "loss": 0.2654,
      "step": 2200
    },
    {
      "epoch": 0.88,
      "eval_loss": 0.901281476020813,
      "eval_runtime": 15.6684,
      "eval_samples_per_second": 16.339,
      "eval_steps_per_second": 16.339,
      "step": 2200
    },
    {
      "epoch": 0.884,
      "grad_norm": 0.7116232514381409,
      "learning_rate": 2.441666666666667e-06,
      "loss": 0.1573,
      "step": 2210
    },
    {
      "epoch": 0.888,
      "grad_norm": 1.4603861570358276,
      "learning_rate": 2.3583333333333338e-06,
      "loss": 0.1968,
      "step": 2220
    },
    {
      "epoch": 0.892,
      "grad_norm": 1.9450116157531738,
      "learning_rate": 2.2750000000000002e-06,
      "loss": 0.2963,
      "step": 2230
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.9971776604652405,
      "learning_rate": 2.191666666666667e-06,
      "loss": 0.1382,
      "step": 2240
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.5222877264022827,
      "learning_rate": 2.1083333333333336e-06,
      "loss": 0.2122,
      "step": 2250
    },
    {
      "epoch": 0.9,
      "eval_loss": 0.9089139699935913,
      "eval_runtime": 15.6759,
      "eval_samples_per_second": 16.331,
      "eval_steps_per_second": 16.331,
      "step": 2250
    }
  ],
  "logging_steps": 10,
  "max_steps": 2500,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.5893398396928e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
