=== Experiment Start: Sat Nov 23 04:37:37 PM UTC 2024 ===
GPU Information:
Sat Nov 23 16:37:37 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-SXM4-40GB          Off | 00000000:00:04.0 Off |                    0 |
| N/A   31C    P0              42W / 400W |      2MiB / 40960MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
=== Running Pipeline ===
INFO:__main__:Initialized pruning pipeline with device: cuda
INFO:__main__:Loading model and data...
INFO:src.model_loader:Model not found locally. Downloading...
INFO:src.model_loader:Downloading model meta-llama/Llama-3.2-1B-Instruct...
INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
INFO:src.model_loader:Saving model to models/Llama-3.2-1B-Instruct"
INFO:src.model_loader:Model saved successfully
INFO:__main__:Building dependency graph...
INFO:src.dependency_graph:Initializing DependencyGraphBuilder for layers 14 to 15
INFO:src.dependency_graph:Building dependency graph for last 20% of layers...
Building Graph:   0%|          | 0/6 [00:00<?, ?it/s]Creating attention groups...

Creating attention groups:   0%|          | 0/2 [00:00<?, ?it/s][ACreating attention groups: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 22.33it/s]
Creating MLP groups...

Creating MLP groups:   0%|          | 0/2 [00:00<?, ?it/s][A
Creating MLP groups:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.66s/it][A
Creating MLP groups: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:07<00:00,  3.58s/it][ACreating MLP groups: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:07<00:00,  3.59s/it]
Building Graph:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 2/6 [00:07<00:14,  3.64s/it]INFO:src.dependency_graph:Starting structural dependency analysis...
Adding structural dependencies...

Processing within-layer dependencies:   0%|          | 0/2 [00:00<?, ?it/s][A
Processing within-layer dependencies: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.47it/s][AProcessing within-layer dependencies: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.46it/s]
INFO:src.dependency_graph:Completed dependency analysis with 525312 edges
Building Graph:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [00:26<00:30, 10.02s/it]WARNING:src.dependency_graph:Found 18 ungrouped parameters in target layers
WARNING:src.dependency_graph:Found 18 ungrouped parameters in target layers

Processing cross-layer dependencies...
Processed layer 14 â†’ 15
Adding dimensional dependencies...
Validating and optimizing graph...
Validating graph structure...
Validating parameter assignments...
Validating parameter assignments...
Optimizing graph structure...
Large graph detected, using SCC-based optimization...
Optimizing using strongly connected components...
Reduced edges by 0.0% (525312 â†’ 525312)
Updating group dependencies...

  0%|          | 0/16448 [00:00<?, ?it/s][A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16448/16448 [00:00<00:00, 399596.35it/s]
Building Graph:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:28<00:14,  7.13s/it]Building Graph:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 4/6 [00:28<00:14,  7.13s/it]
INFO:src.dependency_graph:Built dependency graph with 16448 groups and 525312 dependencies
INFO:src.dependency_graph:Saved dependency graph visualization to experiments/results/dependency_graph.png
INFO:__main__:Calculating importance scores...
INFO:src.importance_scorer:Initialized ImportanceScorer with methods: ['gradient', 'activation', 'fisher']
Generating graph visualization...
Computing layout...
Drawing nodes...
Drawing edges...
Adding labels...
Saving visualization to experiments/results/dependency_graph.png...
Calculating importance scores:   0%|          | 0/16448 [00:00<?, ?it/s]/content/LLM-Compression/src/importance_scorer.py:73: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/content/LLM-Compression/src/importance_scorer.py:141: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
ERROR:src.importance_scorer:Error computing importance for group attn_l14_h0: 'ImportanceScorer' object has no attribute 'calibration_data'
Calculating importance scores:   0%|          | 0/16448 [00:20<?, ?it/s]
ERROR:__main__:Pipeline failed: 'ImportanceScorer' object has no attribute 'calibration_data'
Traceback (most recent call last):
  File "/content/LLM-Compression/run_pipeline.py", line 81, in run
    self._calculate_importance_scores(groups, scorer)
  File "/content/LLM-Compression/run_pipeline.py", line 170, in _calculate_importance_scores
    score = scorer.compute_group_importance(group)
  File "/content/LLM-Compression/src/importance_scorer.py", line 102, in compute_group_importance
    value = methods_map[method](group)
  File "/content/LLM-Compression/src/importance_scorer.py", line 147, in _compute_gradient_importance
    for batch in self._get_batches(batch_size):
  File "/content/LLM-Compression/src/importance_scorer.py", line 168, in _get_batches
    dataset_size = len(self.calibration_data)
AttributeError: 'ImportanceScorer' object has no attribute 'calibration_data'
Traceback (most recent call last):
  File "/content/LLM-Compression/run_pipeline.py", line 315, in <module>
    main()
  File "/content/LLM-Compression/run_pipeline.py", line 312, in main
    pipeline.run()
  File "/content/LLM-Compression/run_pipeline.py", line 81, in run
    self._calculate_importance_scores(groups, scorer)
  File "/content/LLM-Compression/run_pipeline.py", line 170, in _calculate_importance_scores
    score = scorer.compute_group_importance(group)
  File "/content/LLM-Compression/src/importance_scorer.py", line 102, in compute_group_importance
    value = methods_map[method](group)
  File "/content/LLM-Compression/src/importance_scorer.py", line 147, in _compute_gradient_importance
    for batch in self._get_batches(batch_size):
  File "/content/LLM-Compression/src/importance_scorer.py", line 168, in _get_batches
    dataset_size = len(self.calibration_data)
AttributeError: 'ImportanceScorer' object has no attribute 'calibration_data'
